lr設為1e-3時有不錯的效果
concat_frames以此次作業來說是越大會有越佳的準確度，
但當使用約35時就會需要約16g的ram，
模型使用BIGRU與2DCNN-GRU並在訓練完後以一層Linear的模型連接當作ensemble方法作為輸出，
使用GRU而非LSTM是因效率問題。
雖然有許多研究表明使用CNN可以起到特徵萃取的效果，
但在此次作業中不知為何使用CNN搭配GRU(81%)並沒有勝過無使用CNN的GRU(83%)，
但將兩者以上述方式ensemble後成功使準確率上升約1%。
此次作業準確率提升的關鍵在於RNN使用與模型層數，
只要有使用RNN並建立較深模型應該就可以有不錯結果。

